# -*- coding: utf-8 -*-
"""notrainingPY.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BspHMtx_q8MdU2pG4o7-54A06D2bu2xj
"""

import torch
from torch import nn
#import torch.nn.functional as F
#import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import gluonnlp as nlp
import numpy as np
#from tqdm import tqdm, tqdm_notebook
import pandas as pd

# kobert
from kobert.utils import get_tokenizer
from kobert.pytorch_kobert import get_pytorch_kobert_model

# transformers
#from transformers import AdamW
#from transformers.optimization import get_cosine_schedule_with_warmup

# BERT 모델, Vocabulary 불러오기->pkl로 학습된 모델을 불러오니까 이제 bert_model은 필요가 없어졌고, vocab만 따로 저장해서 불러올수 없을지..
bertmodel, vocab = get_pytorch_kobert_model()

# 문장에서 특수문자 제거하기
import re


def cleanText(input):
    clean = re.sub('[-=+,#/\?:^$.@*\"※~&%ㆍ!』\\‘|\(\)\[\]\<\>`\'…》]', '', input)
    return clean


chatbot_data = pd.read_excel('user_conversation.xlsx')

# answer json 파일 열기

import json
# from google.colab import files

with open('answersample.json',encoding="UTF8") as json_file:
    answer_data = json.load(json_file)


class BERTDataset(Dataset):
    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,
                 pad, pair):
        transform = nlp.data.BERTSentenceTransform(
            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)

        self.sentences = [transform([i[sent_idx]]) for i in dataset]
        self.labels = [np.int32(i[label_idx]) for i in dataset]

    def __getitem__(self, i):
        return (self.sentences[i] + (self.labels[i],))

    def __len__(self):
        return (len(self.labels))


# Setting parameters
max_len = 64
batch_size = 64
warmup_ratio = 0.1
num_epochs = 40
max_grad_norm = 1
log_interval = 200
learning_rate = 5e-5


class BERTClassifier(nn.Module):
    def __init__(self,
                 bert,
                 hidden_size=768,
                 num_classes=10,  ##클래스 수 조정##
                 dr_rate=None,
                 params=None):
        super(BERTClassifier, self).__init__()
        self.bert = bert
        self.dr_rate = dr_rate

        self.classifier = nn.Linear(hidden_size, num_classes)
        if dr_rate:
            self.dropout = nn.Dropout(p=dr_rate)

    def gen_attention_mask(self, token_ids, valid_length):
        attention_mask = torch.zeros_like(token_ids)
        for i, v in enumerate(valid_length):
            attention_mask[i][:v] = 1
        return attention_mask.float()

    def forward(self, token_ids, valid_length, segment_ids):
        attention_mask = self.gen_attention_mask(token_ids, valid_length)

        _, pooler = self.bert(input_ids=token_ids, token_type_ids=segment_ids.long(),
                              attention_mask=attention_mask.float().to(token_ids.device))
        if self.dr_rate:
            out = self.dropout(pooler)
        return self.classifier(out)


# GPU 사용 시
# device = torch.device("cuda:0")
device = torch.device("cpu")

# BERT 모델 불러오기
# model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)

# """training은 생략. 미리 학습된 모델을 불러오는것이 목표"""

# 네이버 맞춤법 교정기 기반 라이브러리

from hanspell import spell_checker


def spellCheck(input):
    checked = spell_checker.check(input)
    # print(checked.as_dict())
    # print(checked.as_dict()['checked'])
    return checked.as_dict()['checked']


import random


def getAnswer(index):
    # answers=[]
    for tg in answer_data["intents"]:
        if tg['tag'] == str(index):
            answers = tg['answer']
    ans = random.choice(answers)
    # return answers
    return ans


#import joblib
import pickle
#import os
#from pathlib import Path
#import dill


# loaded_model = joblib.load('./bert_model.pkl')

# # model= joblib.load("bert_model.pkl")
# with open('bert_model.pkl', 'rb') as f:
#     loaded_model = pd.read_pickle(f)
#     # print("loading model success")
import builtins
loaded_model=builtins.open('bert_model.pkl', 'r')
# with open('bert_model.pkl', 'rb') as file:
#     loaded_model = pickle.load(file)

# 수정본
tokenizer = get_tokenizer()

tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)


def predict(predict_sentence):
    predict_sentence = spellCheck(predict_sentence)
    predict_sentence = cleanText(predict_sentence)

    print("전처리 후: " + predict_sentence)

    data = [predict_sentence, '0']
    # print(data) #['물 줄까', '0']

    dataset_another = [data]
    # print(dataset_another) #[['물 줄까', '0']]

    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)

    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=2)

    loaded_model.eval()

    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):
        token_ids = token_ids.long().to(device)
        segment_ids = segment_ids.long().to(device)

        valid_length = valid_length
        label = label.long().to(device)

        out = loaded_model(token_ids, valid_length, segment_ids)
        tmp = out.detach().cpu().numpy()
        maxProb = np.max(tmp[0])
        # print(out,"\n")
        # print(tmp,"\n")
        print("확률: ", maxProb)
        test_eval = []
        idx = -1
        for i in out:
            logits = i
            logits = logits.detach().cpu().numpy()

            idx = np.argmax(logits)

            if idx == 0:
                test_eval.append("곰팡이")
            elif idx == 1:
                test_eval.append("물주기")
            elif idx == 2:
                test_eval.append("분갈이방법")
            elif idx == 3:
                test_eval.append("온도")
            elif idx == 4:
                test_eval.append("웃자람")
            elif idx == 5:
                test_eval.append("인조조명")
            elif idx == 6:
                test_eval.append("잎의질병")
            elif idx == 7:
                test_eval.append("잡초")
            elif idx == 8:
                test_eval.append("튜토리얼")
            elif idx == 9:
                test_eval.append("해충")
        print(">> 질문 카테고리: " + test_eval[0])

        answer = getAnswer(idx)
        print(">> 답변: " + answer)
        return answer  # 추가
        # for i in answer:
        #    print(">> 답변: "+i)


# predict("분갈이 방법 알려줘")

######## colab flask ngrok ######
#
# from flask import Flask, request, jsonify
# from flask_ngrok import run_with_ngrok
# from flask import make_response
#
# app = Flask(__name__)
# run_with_ngrok(app)  # Start ngrok when app is run
#
#
# # http://xxxxxx.ngrok.io/?msg=안녕
# @app.route("/", methods=['GET', 'POST'])
# def chatBot():
#     parameter_dict = request.args.to_dict()
#     if len(parameter_dict) == 0:
#         s = "리피에게 궁금한걸 물어봐주세요~"
#     else:
#         question = request.args.get('msg')
#         s = predict(question)
#
#     result = json.dumps({"cnt": s}, ensure_ascii=False)
#     res = make_response(result)
#     return res, 200, {'content-type': 'application/json'}
#
#
# if __name__ == '__main__':
#     app.run()  # If address is in use, may need to terminate other sessions:
#     # Runtime > Manage Sessions > Terminate Other Sessions
#########################

from flask import Flask, url_for, request, jsonify
app = Flask(__name__)

@app.route('/', methods=['GET', 'POST'])
def chat():
    message = request.args.get('msg')
    ans = "answer for > "+message
    return jsonify(answer=ans)

if __name__=='__main__':
    #app.run(host='10.200.7.82',debug=True)
    app.run(host='0.0.0.0', port=8080)
